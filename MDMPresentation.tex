\section{Une réponse : le master data management}

\subsection{Présentation du procédé et objectifs} 

Le Master Data Management, traduit en français par Gestion des données de références, est une discipline des technologies de l'information ayant pour objectif de définir des concepts et méthodes visant à établir au sein d'un système d'information un schéma de base de données de références considérées commes fiables.\\
Outre cela, le Master Data Management engloble aussi les disciplines d'intégration, d'exposition et d'utilisation de ces données de références au sein d'un système d'information d'entreprise, autant du coté opérationel que analytique.\\
Ce procédé, permet de répondre en partie à la problématique de la qualité des données, en définissant un cadre de données dites de références, sures, et limite ainsi l'entropie des données intégrées au DataWarehouse, mais n'effectue pas à proprement parler de nettoyage des données, thème qui sera abordé dans la suite de la synthèse\\

L'hypothèse de base est la suivante : \textit{"En assurant la qualité sur les données de références, on limite les erreurs lors de l'alimentation et l'exploitation de l'entrepot de données"}\\

\subsection{Données, de quoi parle t'on ?}

\subsubsection{Donnée Transactionnelle}

Chaque opération effectuée dans l'entreprise génère des données. Par exemple lors d'un achat
les données générées sont (date de l'achat, qte produit acheté, montant transaction et cie...)
Des bases de données basées sur de l'OLTP sont utilisées pour la gestion de ce genre de transactions.
Des techniques de gestion de ces données existent, pour gérer ces données, notamment via le nettoyages par données de références, que nous aborderons dans la suite de cette synthèse.

\subsubsection{Donnée Analytique}

Les données analytiques sont générées à partir des bases de données transactionnelles et des bases de données de références.\\
Il s'agit ici de traiter des données transactionelles sur le plus ou moins long termes, les traitements 
et l'exploitation étants orientés en fonction de grands axes.\\
Deux principales approches se distinguent dans le monde de la business intelligence :
\begin{itemize}
\item Modélisation OLAP : Transformation des entrepôts de données d'entreprises en "hypercubes", permettant une exploitation facilitée (création de rapports, tableaux d'indicateurs...)
\item Datamining : Recherche de regroupements de tuples en fonction de leurs attributs, dans les bases de données d'entreprise, de façon à effectuer de l'analyse prédictive entre-autres. Un exemple concret est le "pattern" de navigation internet d'un utilisateur moyen, permettant au final de "prédire" quelle sera sa prochaine étape de navigation
\end{itemize}

\subsubsection{Données de références, késako ? }

Les données de références sont un sous enssemble des données opérationelles, qui ont la praticularité de ne pas êtres issues d'opération de transactions. Ainsi elle possèdent une certaine constance dans le temps, qui n'est cependant pas une invariance, ces données pouvant être modifiées, complétées voire étendues. Ce sont ces mêmes données qui vont définir les axes d'exploration, d'exploitation et d'analyse.\\
On différencie trois grandes catégories de données de références.

\begin{itemize}
\item Produit : Chaque entreprise possède une quantité de réféence produits, qui peuvent êtres transersaux à plusieurs secteurs de l'entreprise. Typiquement, un produit pourra être référencé par une documentation technique issue d'un bureau d'étude, une opération de vente  ou encore un référenciel fournisseur. L'unicité devra donc être assurée sur l'enssemble des entrées dans ce domaine.
\item Tiers : De façon similaires, les "tiers" d'entreprises sont aussi considérés comme données de références. Par tiers nous entendons toutes personne ou entité ayant une intéraction possible avec le système d'information, typiquement un collaborateur, un client ou encore un fournisseur.
\item Finance  : Les données de finances sont des informations critiques pour le fonctionnement de l'entreprise, obligatoire en ce qui concerne n'importe quel aspect légal et primoridal en ce qui concerne le pilotage des activités. Ces deux approches sont intégrées à la gestion de données de références.
\end{itemize}

\subsubsection{Pourquoi définir un parc de données de références de qualité ?}

Comme expliqué auparavant, les données de références au sein d'un système d'information servent d'axes d'exploitation et d'analyse. Ainsi chaque opération effectuée au sein de ce dernier est obligatoirement rattachée à une ou plusieurs données de référence. Si celles-ci sont corrompues, fausses, non unifiées, le risque d'augmentation de l'entropie au sein du data warehouse s'en trouve décuplé.\\
Par exemple, dans un repère orthogonal de dimension 3, caractérisé par les axes (x,y,z), positionner un point aux coordonées (1,2,3) est quelque chose de relativement aisé, si et seulement si les valeurs 1,2 et 3 des axes sont garanties comme unique.
Emettons alors l'hypothèse que non, les valeurs présentes ne sont pas uniques... La question de l'insertion d'un point aux coordonées (1,2,3) se révelle alors beaucoup plus complexe, quelle valeur choisir ? \\ 
Nous nous retrouverions automatiquement en face d'un parc de n valeurs possédant toutes les caractéristiques (1,2,3) ... différentes !\\
Autre chose, recherchons maintenant tout les points résolvant la condition y = 2, ce qui peut s'apparenter à la recherche de caractéristique commune pour des entrées produit dans le cas réel.
La encore, si "2 possède plusieurs valeurs" dans le repère, la tâche de regroupement s'avère encore plus complexe.\\
Imaginez les risques, sur une base de données opérationelles, avec un nombre de tuples extrêmement grand ?\\

\subsection{Positionnement au sein du SI de l'entreprise}

\subsubsection{ Un peu d'histoire...}

Historiquement, l'âge (pas tant) de pierre (que ça) du système d'information, chaque application opérationelle possédait son propre SGBD dédié à l'application... Celle-ci ne possédait que les données qui lui étaient utiles, que ce soit de référence, ou de transaction.\\
Le problème de la propagation des mises à jour est alors posé, car laissé à la responsabilité de l'opérateur, et comme le dit l'adage " La seule source d'erreur possible dans un ordinateur se trouve entre la chaise et le clavier !".\\
La continuité logique des choses est donc d'essayer de "faire communiquer" les différents SGBDs entre eux... Vient donc la problématique de l'intégration n-carrée : chaque application est raccordée directement aux multiples bases de donnée qu'elle utilise, sans réel moyen de controle de la mise à jour de ces dernières... Fort risque de corruption lors de la propagation de données, de création de doublons sur certaines entrées et aucune trace des modifications portées. \\
Ce système s'est donc révélé catastrophique en terme de maintenance et de qualité des données, mais le problème avait au moins le mérite d'être identifié : il faut contrôler et uniformiser les modes de communication entre les différentes bases de données\\

\subsubsection{ EAI : Intégration d'application opérationnelles dans le SI d'entreprise}

Compte-tenu des expériences décrites précédemment, les développeurs ont orienté la démarche vers la création d'un bus commun de communication entre les différentes  entités du système d'information. Ainsi ce service fourni sera en charge de l'historisation et du transit des données de l'entreprise le tout de façon générique, moyennant le développement de services "connecteurs" entre les applications et le système de communication, appelé Enterprise Service Bus, ou ESB.\\

\begin{itemize}

\item Applications Opérationnelles : Applications métier de l'entreprise, raccordées à l'ESB, 

\item Synchronisation des données basées sur les méta données. Toutes les informations traitant 
des opérations à effectuer sur les différentes bases sont stockées à part. Ainsi la tâche de synchronisation
du contenu est externalisée. Cela est aussi appelé ESB.

\item Les fonctionnalités clés des applications métiers sont maintenant exposées  comme "services" 
dans un système d'orchestration. Ainsi, nous pouvons définir plusieurs processus d'orchestrations, 
comme successions de services. En ce qui concerne le MDM, il ne s'agit pas de seulement être en A2A 
(Application to application), mais aussi d'exposer les données de références à la couche d'orchestration.

\end{itemize}

\subsubsection{Limites du modèle EAI \& SOA}


\subsection{Fonctionnement du MDM dans un système d'information d'entreprise}

\subsubsection{Principe de fonctionnement}

\subsubsection{Gestion spécifique selon le type de la donnée de référence et impact}

\paragraph{Référence tiers}

\paragraph{Référence produit}

\paragraph{Référence financière}

\subsubsection{Business Intelligence et Master Data Management}

\subsection{Présentation des offres du marché}

\subsubsection{Oracle}

\subsubsection{IBM}


